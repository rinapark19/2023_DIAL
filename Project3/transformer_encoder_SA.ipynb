{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4891,"status":"ok","timestamp":1688958571310,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"SyzzYvjovTwy","outputId":"545e0f77-a286-4ba0-fbaf-b49ee77f1906"},"outputs":[],"source":["!pip install torch\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","import os\n","os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n","os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\""]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":319,"status":"ok","timestamp":1688967233166,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"s7GwK3aKvkf5"},"outputs":[],"source":["class MultiHeadAttention(nn.Module):\n","  def __init__(self, embedding_dim, num_heads = 8):\n","    super(MultiHeadAttention, self).__init__()\n","    self.embedding_dim = embedding_dim\n","    self.num_heads = num_heads\n","\n","    assert embedding_dim % self.num_heads == 0\n","\n","    self.projection_dim = embedding_dim // num_heads\n","    self.query_dense = nn.Linear(embedding_dim, embedding_dim)\n","    self.key_dense = nn.Linear(embedding_dim, embedding_dim)\n","    self.value_dense = nn.Linear(embedding_dim, embedding_dim)\n","    self.dense = nn.Linear(embedding_dim, embedding_dim)\n","\n","  def scaled_dot_product_attention(self, query, key, value):\n","    matmul_qk = torch.matmul(query, key.transpose(-2, -1))\n","    depth = torch.tensor(key.shape[-1], dtype=torch.float32)\n","    logits = matmul_qk / torch.sqrt(depth)\n","    attention_weights = F.softmax(logits, dim=-1)\n","    output = torch.matmul(attention_weights, value)\n","    return output, attention_weights\n","\n","  def split_heads(self, x, batch_size):\n","    x = x.view(batch_size, -1, self.num_heads, self.projection_dim)\n","    return x.transpose(1, 2)\n","\n","  def forward(self, inputs):\n","    batch_size = inputs.size(0)\n","    query = self.query_dense(inputs)\n","    key = self.key_dense(inputs)\n","    value = self.value_dense(inputs)\n","    query = self.split_heads(query, batch_size)\n","    key = self.split_heads(key, batch_size)\n","    value = self.split_heads(value, batch_size)\n","    scaled_attention, _ = self.scaled_dot_product_attention(query, key, value)\n","    scaled_attention = scaled_attention.transpose(1, 2)\n","    concat_attention = scaled_attention.reshape(batch_size, -1, self.embedding_dim)\n","    outputs = self.dense(concat_attention)\n","    return outputs"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":359,"status":"ok","timestamp":1688967234885,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"iTuAJKhm8C2-"},"outputs":[],"source":["class TransformerBlock(nn.Module):\n","  def __init__(self, embedding_dim, num_heads, dff, rate = 0.1):\n","    super(TransformerBlock, self).__init__()\n","    self.att = MultiHeadAttention(embedding_dim, num_heads)\n","    self.ffn = nn.Sequential(\n","        nn.Linear(embedding_dim, dff),\n","        nn.ReLU(),\n","        nn.Linear(dff, embedding_dim)\n","    )\n","    self.layernorm1 = nn.LayerNorm(embedding_dim, eps = 1e-6)\n","    self.layernorm2 = nn.LayerNorm(embedding_dim, eps = 1e-6)\n","    self.dropout1 = nn.Dropout(rate)\n","    self.dropout2 = nn.Dropout(rate)\n","\n","  def forward(self, inputs):\n","    attn_output = self.att(inputs)\n","    attn_output = self.dropout1(attn_output)\n","    out1 = self.layernorm1(inputs + attn_output)\n","    ffn_output = self.ffn(out1)\n","    ffn_output = self.dropout2(ffn_output)\n","    return self.layernorm2(out1 + ffn_output)"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":511,"status":"ok","timestamp":1688967236889,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"SunocgEn8tuu"},"outputs":[],"source":["class TokenAndPositionEmbedding(nn.Module):\n","  def __init__(self, max_len, vocab_size, embedding_dim):\n","    super(TokenAndPositionEmbedding, self).__init__()\n","    self.token_emb = nn.Embedding(vocab_size, embedding_dim)\n","    self.pos_emb = nn.Embedding(max_len, embedding_dim)\n","\n","  def forward(self, x):\n","    positions = torch.arange(0, x.size(1), dtype=torch.long).unsqueeze(0).to(x.device)\n","    positions = self.pos_emb(positions)\n","    x = self.token_emb(x)\n","    return x + positions"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1242,"status":"ok","timestamp":1688967239250,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"nxBdYSql9GRt","outputId":"5f6a3b2c-cd8d-448c-e3b9-2b939557ec5c"},"outputs":[],"source":["import pandas as pd\n","\n","train = pd.read_csv(\"/content/drive/MyDrive/랩인턴/sentimental_analysis/train.csv\")\n","test = pd.read_csv(\"/content/drive/MyDrive/랩인턴/sentimental_analysis/test (1).csv\")\n","\n","train_new_row = train.columns\n","test_new_row = test.columns\n","\n","train.columns = ['y_1', 'y_2', 'x']\n","train = train.append(pd.Series(), ignore_index=True)\n","train.loc[0] = train_new_row\n","\n","test.columns = ['y_1', 'y_2', 'x']\n","test = test.append(pd.Series(), ignore_index=True)\n","test.loc[0] = test_new_row\n","\n","train.dropna(inplace = True)\n","test.dropna(inplace= True)\n","\n","train.reset_index(drop=True)\n","test.reset_index(drop=True)\n","\n","X_train = list(train['x'])\n","y_train = list(train['y_1'])\n","\n","X_test = list(test['x'])\n","y_test = list(test['y_1'])\n","\n","y_train[0] = 1\n","y_test[0] = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6654,"status":"ok","timestamp":1688967247035,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"k_wk5TEYAgYf","outputId":"3de50b97-6701-4a50-c2fc-f893f7d46a6a"},"outputs":[],"source":["!pip install transformers\n","from transformers import BertTokenizer\n","\n","max_len = 512\n","vocab_size = 22000\n","\n","tokenizer = BertTokenizer(vocab_file = \"/content/drive/MyDrive/랩인턴/translator1/wiki-vocab.txt\", max_length = max_len)"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"_VwuMsSPC8z-"},"outputs":[],"source":["#@title 기본 제목 텍스트\n","pad_token_id = tokenizer.pad_token_id\n","\n","train_x = []\n","test_x = []\n","\n","for x in X_train:\n","  x = tokenizer.encode(x, max_length  = max_len, truncation=True)\n","  rest = max_len - len(x)\n","  x = torch.tensor(x + [pad_token_id] * rest)\n","  train_x.append(x)\n","\n","for x in X_test:\n","  x = tokenizer.encode(x, max_length= max_len, truncation=True)\n","  rest = max_len - len(x)\n","  x = torch.tensor(x + [pad_token_id] * rest)\n","  test_x.append(x)"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":23,"status":"ok","timestamp":1688967247037,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"5_TXwfHqF-jS"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class CustomDataset(Dataset):\n","  def __init__(self, data, targets, tokenizer):\n","    self.data =data\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    text = self.data[idx]\n","    tokens = self.tokenizer.encode(text, add_special_tokens=True)\n","    label = 1 if self.targets[idx] == 1.0 else 0\n","    return torch.tensor(tokens), torch.tensor(label)\n","\n","def collate_fn(batch):\n","  inputs, targets = zip(*batch)\n","  inputs = pad_sequence(inputs, padding_value=0, batch_first=True)\n","  targets = torch.stack(targets, dim=0)\n","  return inputs, targets"]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1688967247038,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"ZogTTJeZGeEb"},"outputs":[],"source":["train_dataset = CustomDataset(X_train, y_train, tokenizer)\n","test_dataset = CustomDataset(X_test, y_test, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn = collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":594653,"status":"ok","timestamp":1688959307217,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"HcCUyXwcDay6","outputId":"da5ef435-d1ba-4680-da8b-27d7f6211437"},"outputs":[],"source":["embedding_dim = 32\n","num_heads = 2\n","dff = 32\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class MyModel(nn.Module):\n","  def __init__(self, max_len, vocab_size, embedding_dim, num_heads, dff):\n","    super(MyModel, self).__init__()\n","    self.embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n","    self.transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n","    self.dropout1 = nn.Dropout(0.1)\n","    self.linear1 = nn.Linear(embedding_dim, 20)\n","    self.dropout2 = nn.Dropout(0.1)\n","    self.linear2 = nn.Linear(20, 2)\n","\n","  def forward(self, inputs):\n","    x = self.embedding_layer(inputs)\n","    x = self.transformer_block(x)\n","    x = torch.mean(x, dim=1)\n","    x = x.squeeze(-1)\n","    x = self.dropout1(x)\n","    x = self.linear1(x)\n","    x = self.dropout2(x)\n","    x = self.linear2(x)\n","    return F.log_softmax(x, dim=-1)\n","\n","model = MyModel(max_len, vocab_size, embedding_dim, num_heads, dff).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(2):\n","  model.train()\n","  total_loss = 0.0\n","  total_samples = 0\n","  print(\"epoch: \", epoch)\n","  for inputs, targets in train_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    optimizer.zero_grad()\n","    output = model(inputs)\n","\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.item() * len(inputs)\n","    total_samples += len(inputs)\n","  epoch_loss = total_loss / total_samples\n","  print(\"Epoch %d, Training Loss: %.4f\" %(epoch + 1, epoch_loss))"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2613,"status":"ok","timestamp":1688959334488,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"7C6b7brZLJpg","outputId":"b3770e13-23e8-4a39-a036-62a8be79497d"},"outputs":[{"name":"stdout","output_type":"stream","text":["테스트 정확도: 0.7022\n"]}],"source":["model.eval()\n","with torch.no_grad():\n","  correct = 0\n","  total = 0\n","  for inputs, targets in test_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    output = model(inputs)\n","    _, predicted = torch.max(output, dim=1)\n","    total += targets.size(0)\n","    correct += (predicted == targets).sum().item()\n","\n","accuracy = correct / total\n","print(\"테스트 정확도: %.4f\" % accuracy)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bC6lkdNvU_fI"},"outputs":[],"source":["def predict_sentiment(text):\n","  # token_ids = tokenizer(text)\n","  # token_ids = tokenizer.convert_tokens_to_ids(token_ids)\n","  # token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n","\n","  token_ids = tokenizer.encode(text)\n","  token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n","  token_ids = pad_sequence(token_ids, padding_value=0, batch_first=True)\n","\n","  with torch.no_grad():\n","    output = model(token_ids)\n","    _, preds = torch.max(output, dim=1)\n","\n","    print(preds)\n","\n","  if preds.item() == 1:\n","    print(\"긍정 리뷰입니다.\")\n","  else:\n","    print(\"부정 리뷰입니다.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2,"status":"ok","timestamp":1688937396841,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"geN2kHv1Wqvk","outputId":"ebf6b9fc-c787-4024-9121-d7a2268b63f9"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([1], device='cuda:0')\n","긍정 리뷰입니다.\n"]}],"source":["predict_sentiment(\"너무 좋아요 ㅎㅎ\")"]},{"cell_type":"markdown","metadata":{"id":"4qe9995FkvB3"},"source":["*2*. Multi class classification"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":357,"status":"ok","timestamp":1688967250142,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"ib2DBXDSkxYm"},"outputs":[],"source":["from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pad_sequence\n","\n","class CustomDataset(Dataset):\n","  def __init__(self, data, targets, tokenizer):\n","    self.data =data\n","    self.targets = targets\n","    self.tokenizer = tokenizer\n","\n","  def __len__(self):\n","    return len(self.data)\n","\n","  def __getitem__(self, idx):\n","    text = self.data[idx]\n","    tokens = self.tokenizer.encode(text, add_special_tokens=True)\n","    label = torch.tensor(self.targets[idx], dtype=torch.long)\n","    return torch.tensor(tokens), label\n","\n","def collate_fn(batch):\n","  inputs, targets = zip(*batch)\n","  inputs = pad_sequence(inputs, padding_value=0, batch_first=True)\n","  targets = torch.stack(targets, dim=0)\n","  return inputs, targets"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":317,"status":"ok","timestamp":1688967252029,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"S2CDZjbPlV6-"},"outputs":[],"source":["X_train = list(train['x'])\n","y_train = list(train['y_2'])\n","\n","X_test = list(test['x'])\n","y_test = list(test['y_2'])\n","\n","y_train[0] = 5\n","y_test[0] = 2"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":431,"status":"ok","timestamp":1688968244613,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"1UF6ltNKV6ca"},"outputs":[],"source":["for i in range(len(y_train)):\n","  y = y_train[i]\n","  y_train[i] = y -1\n","\n","for i in range(len(y_test)):\n","  y = y_test[i]\n","  y_test[i] = y - 1"]},{"cell_type":"code","execution_count":26,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1688967252961,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"5r5Jt0RDk3rQ"},"outputs":[],"source":["train_dataset = CustomDataset(X_train, y_train, tokenizer)\n","test_dataset = CustomDataset(X_test, y_test, tokenizer)\n","\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n","test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False, collate_fn = collate_fn)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":774950,"status":"ok","timestamp":1688969025383,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"UlGAmQLllEuF","outputId":"2e2632b6-d6c4-4130-aa57-1be73b0bda9c"},"outputs":[],"source":["embedding_dim = 32\n","num_heads = 2\n","dff = 32\n","\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","class MyModel(nn.Module):\n","  def __init__(self, max_len, vocab_size, embedding_dim, num_heads, dff):\n","    super(MyModel, self).__init__()\n","    self.embedding_layer = TokenAndPositionEmbedding(max_len, vocab_size, embedding_dim)\n","    self.transformer_block = TransformerBlock(embedding_dim, num_heads, dff)\n","    self.dropout1 = nn.Dropout(0.1)\n","    self.linear1 = nn.Linear(embedding_dim, 20)\n","    self.dropout2 = nn.Dropout(0.1)\n","    self.linear2 = nn.Linear(20, 5)\n","\n","  def forward(self, inputs):\n","    x = self.embedding_layer(inputs)\n","    x = self.transformer_block(x)\n","    x = torch.mean(x, dim=1)\n","    x = x.squeeze(-1)\n","    x = self.dropout1(x)\n","    x = self.linear1(x)\n","    x = self.dropout2(x)\n","    x = self.linear2(x)\n","    return F.log_softmax(x, dim=-1)\n","\n","model = MyModel(max_len, vocab_size, embedding_dim, num_heads, dff).to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n","criterion = nn.CrossEntropyLoss()\n","\n","for epoch in range(2):\n","  model.train()\n","  total_loss = 0.0\n","  total_samples = 0\n","  print(\"epoch: \", epoch)\n","  for inputs, targets in train_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    optimizer.zero_grad()\n","    output = model(inputs)\n","\n","    loss = criterion(output, targets)\n","    loss.backward()\n","    optimizer.step()\n","\n","    total_loss += loss.item() * len(inputs)\n","    total_samples += len(inputs)\n","  epoch_loss = total_loss / total_samples\n","  print(\"Epoch %d, Training Loss: %.4f\" %(epoch + 1, epoch_loss))"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4568,"status":"ok","timestamp":1688969543394,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"r1-Kpc5_lME0","outputId":"c3da03ff-80ca-4cb6-b3d0-1fc7ffe6d955"},"outputs":[{"name":"stdout","output_type":"stream","text":["RMSE:  1.8568295394694192\n"]}],"source":["import numpy as np\n","\n","def calculate_rmse(predictions, targets):\n","  mse = np.mean((predictions - targets) ** 2)\n","  rmse = np.sqrt(mse)\n","  return rmse\n","\n","predictions = []\n","targets_list = []\n","\n","model.eval()\n","with torch.no_grad():\n","  for inputs, targets in test_loader:\n","    inputs = inputs.to(device)\n","    targets = targets.to(device)\n","\n","    output = model(inputs)\n","    _, predicted = torch.max(output, dim=1)\n","    predictions.extend(predicted.cpu().numpy())\n","    targets_list.extend(targets.cpu().numpy())\n","\n","predictions = np.array(predictions)\n","targets = np.array(targets_list)\n","rmse = calculate_rmse(predictions, targets)\n","\n","print(\"RMSE: \", rmse)"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":281,"status":"ok","timestamp":1688969774971,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"7MAqwWNOblh8"},"outputs":[],"source":["def predict_score(text):\n","  token_ids = tokenizer.encode(text)\n","  token_ids = torch.tensor(token_ids).unsqueeze(0).to(device)\n","  token_ids = pad_sequence(token_ids, padding_value=0, batch_first=True)\n","\n","  with torch.no_grad():\n","    output = model(token_ids)\n","    predicted_class = torch.argmax(output, dim=1)\n","    predicted_score = predicted_class.item() + 1\n","  return predicted_score"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":309,"status":"ok","timestamp":1688969793675,"user":{"displayName":"박채린","userId":"04948549455345468544"},"user_tz":-540},"id":"hIaBFJJrcXJX","outputId":"b379c409-a39e-4092-ad53-f4f4dc87c2f5"},"outputs":[{"data":{"text/plain":["2"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["predict_score(\"별로예요\")"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyMxdgFqp1l2tbZAVswSvVJe","gpuType":"T4","mount_file_id":"1wFHFH1mXEM0NN96FR3KYP-95HGL_4h30","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
